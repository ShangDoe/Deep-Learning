{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ced190-2927-4292-a587-09229ea3d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "70652e79-1d77-4e1e-b137-1be259d6f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:\\\\Users\\\\batlagh\\\\datasets\\\\UTKFace\\\\crop_part1\\\\\"\n",
    "image_size = (224, 224) \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605077ab-0071-45af-937f-822303dfd7c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Age Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d5ed7f7c-4fa0-4cf9-b2b3-923334dfb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_age(age):\n",
    "    if age <= 25:\n",
    "        return 0  # Young\n",
    "    elif 25 < age <= 50:\n",
    "        return 1  # Middle\n",
    "    else:\n",
    "        return 2  # Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1a506b4-b488-449a-9211-f7514b458159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    temp = tf.strings.split(file_path, os.sep)[-1]\n",
    "    \n",
    "    age_str = tf.strings.split(temp, sep='_')[0]\n",
    "    age = tf.strings.to_number(age_str, tf.int32)\n",
    "    \n",
    "    age_category = categorize_age(age)\n",
    "\n",
    "    age_category_one_hot = tf.one_hot(age_category, depth=3)\n",
    "    \n",
    "    return file_path, age_category_one_hot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "567199ed-cbcf-4884-8be9-a0eb5ba77761",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_pattern = os.path.join(data_dir, '*.jpg')\n",
    "dataset = tf.data.Dataset.list_files(file_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7636f1c6-7c61-465f-bda3-e83abb50804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(process_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e5e74c2c-4bc7-4950-87b3-224e12f7ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path, age_category):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = image / 255.0\n",
    "    \n",
    "    return image, age_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "137f5587-347d-4cec-8dc6-c8e72504447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e768fd8-6ac9-41f0-8452-1ec3994b6f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c26db58a-5e25-47ca-9bf3-b872a6af0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cache().shuffle(len(dataset)).batch(batch_size=batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b83a043b-e017-400a-94b5-5181e51172a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c349b6a5-9ec3-40b2-a0a2-c596b59eadfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.7)\n",
    "val_size = int(len(dataset) * 0.2) + 1\n",
    "test_size = int(len(dataset) * 0.1)\n",
    "\n",
    "train_size + val_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b5dd1b34-4c07-4bda-aea6-691f6454a0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(train_size)\n",
    "val = dataset.skip(train_size).take(val_size)\n",
    "test = dataset.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "083ae977-1650-4d76-a85c-9f7df20a6555",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "base_model.trainable = False  \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='categorical_crossentropy',  \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd7331ce-2518-4225-b972-70e38017d8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "214/214 [==============================] - 13s 52ms/step - loss: 0.5973 - accuracy: 0.7339 - val_loss: 0.4920 - val_accuracy: 0.7863\n",
      "Epoch 2/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.5025 - accuracy: 0.7794 - val_loss: 0.4859 - val_accuracy: 0.7858\n",
      "Epoch 3/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.4942 - accuracy: 0.7869 - val_loss: 0.4562 - val_accuracy: 0.8125\n",
      "Epoch 4/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.4606 - accuracy: 0.8005 - val_loss: 0.4173 - val_accuracy: 0.8211\n",
      "Epoch 5/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.4428 - accuracy: 0.8051 - val_loss: 0.4424 - val_accuracy: 0.8049\n",
      "Epoch 6/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.4081 - accuracy: 0.8239 - val_loss: 0.3818 - val_accuracy: 0.8412\n",
      "Epoch 7/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.3897 - accuracy: 0.8338 - val_loss: 0.3633 - val_accuracy: 0.8528\n",
      "Epoch 8/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.3734 - accuracy: 0.8382 - val_loss: 0.3217 - val_accuracy: 0.8725\n",
      "Epoch 9/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.3680 - accuracy: 0.8411 - val_loss: 0.3160 - val_accuracy: 0.8755\n",
      "Epoch 10/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.3523 - accuracy: 0.8497 - val_loss: 0.3416 - val_accuracy: 0.8543\n",
      "Epoch 11/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.3178 - accuracy: 0.8652 - val_loss: 0.3062 - val_accuracy: 0.8805\n",
      "Epoch 12/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.3069 - accuracy: 0.8731 - val_loss: 0.2702 - val_accuracy: 0.8982\n",
      "Epoch 13/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.2838 - accuracy: 0.8851 - val_loss: 0.2619 - val_accuracy: 0.8947\n",
      "Epoch 14/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.2750 - accuracy: 0.8874 - val_loss: 0.2411 - val_accuracy: 0.9027\n",
      "Epoch 15/50\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.2634 - accuracy: 0.8949 - val_loss: 0.2555 - val_accuracy: 0.9002\n",
      "Epoch 16/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.2385 - accuracy: 0.9048 - val_loss: 0.2090 - val_accuracy: 0.9224\n",
      "Epoch 17/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.2242 - accuracy: 0.9130 - val_loss: 0.2195 - val_accuracy: 0.9173\n",
      "Epoch 18/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.1943 - accuracy: 0.9264 - val_loss: 0.1758 - val_accuracy: 0.9425\n",
      "Epoch 19/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.1922 - accuracy: 0.9261 - val_loss: 0.1802 - val_accuracy: 0.9294\n",
      "Epoch 20/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.1722 - accuracy: 0.9372 - val_loss: 0.1486 - val_accuracy: 0.9471\n",
      "Epoch 21/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.1702 - accuracy: 0.9372 - val_loss: 0.1449 - val_accuracy: 0.9456\n",
      "Epoch 22/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.1383 - accuracy: 0.9537 - val_loss: 0.1394 - val_accuracy: 0.9516\n",
      "Epoch 23/50\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.1347 - accuracy: 0.9524 - val_loss: 0.1444 - val_accuracy: 0.9446\n",
      "Epoch 24/50\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.1244 - accuracy: 0.9568 - val_loss: 0.0907 - val_accuracy: 0.9763\n",
      "Epoch 25/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.1013 - accuracy: 0.9682 - val_loss: 0.0865 - val_accuracy: 0.9778\n",
      "Epoch 26/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.0952 - accuracy: 0.9699 - val_loss: 0.0675 - val_accuracy: 0.9874\n",
      "Epoch 27/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.0892 - accuracy: 0.9708 - val_loss: 0.0992 - val_accuracy: 0.9577\n",
      "Epoch 28/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.1029 - accuracy: 0.9617 - val_loss: 0.0671 - val_accuracy: 0.9783\n",
      "Epoch 29/50\n",
      "214/214 [==============================] - 10s 49ms/step - loss: 0.0691 - accuracy: 0.9794 - val_loss: 0.0555 - val_accuracy: 0.9879\n",
      "Epoch 30/50\n",
      "214/214 [==============================] - 11s 49ms/step - loss: 0.0697 - accuracy: 0.9798 - val_loss: 0.0842 - val_accuracy: 0.9728\n",
      "Epoch 31/50\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 0.0638 - accuracy: 0.9806 - val_loss: 0.0652 - val_accuracy: 0.9773\n",
      "Epoch 32/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0575 - accuracy: 0.9826 - val_loss: 0.0469 - val_accuracy: 0.9884\n",
      "Epoch 33/50\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.0485 - accuracy: 0.9879 - val_loss: 0.0440 - val_accuracy: 0.9934\n",
      "Epoch 34/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0467 - accuracy: 0.9896 - val_loss: 0.0284 - val_accuracy: 0.9980\n",
      "Epoch 35/50\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 0.0390 - accuracy: 0.9918 - val_loss: 0.0326 - val_accuracy: 0.9934\n",
      "Epoch 36/50\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 0.0453 - accuracy: 0.9870 - val_loss: 0.0317 - val_accuracy: 0.9934\n",
      "Epoch 37/50\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 0.0397 - accuracy: 0.9898 - val_loss: 0.0422 - val_accuracy: 0.9864\n",
      "Epoch 37: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, verbose=True)\n",
    "\n",
    "hist = model.fit(train, validation_data=val, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fdab8b04-1aad-4100-a752-1039829476fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 46ms/step - loss: 0.0463 - accuracy: 0.9873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04629414156079292, 0.9873417615890503]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a10fe14-6286-49a3-b09b-e9a32372cb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"age_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526b31e-81d8-48a1-afcd-44da7ac9071c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Gender Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3d61dcc0-b1b7-4c33-9315-20c83b827bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_paths(file_path):\n",
    "    temp = tf.strings.split(file_path, os.sep)[-1]\n",
    "    gender_str = tf.strings.split(temp, sep=\"_\")[1]\n",
    "    gender = tf.strings.to_number(gender_str, tf.int32)\n",
    "\n",
    "    return file_path, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8fcc81ca-bd77-49c3-94f5-6a532c1583ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = os.path.join(data_dir, \"*.jpg\")\n",
    "dataset = tf.data.Dataset.list_files(file_paths)\n",
    "dataset = dataset.map(process_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e0bdcd8f-6dc5-47ed-baf5-52497ac05672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'C:\\\\Users\\\\batlagh\\\\datasets\\\\UTKFace\\\\crop_part1\\\\21_1_4_20170103225014665.jpg.chip.jpg',\n",
       " 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d5adf3c-d5ce-416b-837e-29673a46e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(image_path, gender):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image = image / 255.0\n",
    "\n",
    "    return image, gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "81488ddf-ed66-4a01-a218-0290b3de40f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.map(load_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e8ba3ab3-fefd-42b0-a510-4db12e7802cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4c4baace-dcb7-4603-8c3c-5743c59ac711",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.cache().shuffle(len(dataset)).batch(batch_size=batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8d681ab4-965e-4fb4-ba47-1407670175d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.7)\n",
    "val_size = int(len(dataset) * 0.2) + 1\n",
    "test_size = int(len(dataset) * 0.1)\n",
    "\n",
    "train_size + val_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cdf0ff3d-ce9b-41f5-a6f1-c6828b67e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(train_size)\n",
    "val = dataset.skip(train_size).take(val_size)\n",
    "test = dataset.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26591761-3f9d-458b-a902-b2af57af0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "base_model.trainable = False  \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',  \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e84a910d-0068-44bc-8177-6e823679b6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "214/214 [==============================] - 14s 54ms/step - loss: 0.4941 - accuracy: 0.7461 - val_loss: 0.4081 - val_accuracy: 0.8044\n",
      "Epoch 2/50\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.4176 - accuracy: 0.7986 - val_loss: 0.3958 - val_accuracy: 0.8231\n",
      "Epoch 3/50\n",
      "214/214 [==============================] - 12s 55ms/step - loss: 0.3905 - accuracy: 0.8160 - val_loss: 0.3446 - val_accuracy: 0.8397\n",
      "Epoch 4/50\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 0.3744 - accuracy: 0.8270 - val_loss: 0.3573 - val_accuracy: 0.8286\n",
      "Epoch 5/50\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 0.3449 - accuracy: 0.8432 - val_loss: 0.3511 - val_accuracy: 0.8296\n",
      "Epoch 6/50\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.3322 - accuracy: 0.8467 - val_loss: 0.3135 - val_accuracy: 0.8644\n",
      "Epoch 7/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.3172 - accuracy: 0.8585 - val_loss: 0.3226 - val_accuracy: 0.8488\n",
      "Epoch 8/50\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 0.2984 - accuracy: 0.8668 - val_loss: 0.2644 - val_accuracy: 0.8841\n",
      "Epoch 9/50\n",
      "214/214 [==============================] - 12s 54ms/step - loss: 0.2853 - accuracy: 0.8725 - val_loss: 0.2673 - val_accuracy: 0.8775\n",
      "Epoch 10/50\n",
      "214/214 [==============================] - 11s 50ms/step - loss: 0.2607 - accuracy: 0.8905 - val_loss: 0.2133 - val_accuracy: 0.9118\n",
      "Epoch 11/50\n",
      "214/214 [==============================] - 12s 54ms/step - loss: 0.2417 - accuracy: 0.8965 - val_loss: 0.2101 - val_accuracy: 0.9189\n",
      "Epoch 12/50\n",
      "214/214 [==============================] - 12s 58ms/step - loss: 0.2423 - accuracy: 0.8928 - val_loss: 0.1965 - val_accuracy: 0.9254\n",
      "Epoch 13/50\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 0.2130 - accuracy: 0.9152 - val_loss: 0.1962 - val_accuracy: 0.9259\n",
      "Epoch 14/50\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 0.2016 - accuracy: 0.9204 - val_loss: 0.1700 - val_accuracy: 0.9405\n",
      "Epoch 15/50\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 0.1925 - accuracy: 0.9226 - val_loss: 0.1721 - val_accuracy: 0.9425\n",
      "Epoch 16/50\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 0.1747 - accuracy: 0.9301 - val_loss: 0.1322 - val_accuracy: 0.9496\n",
      "Epoch 17/50\n",
      "214/214 [==============================] - 12s 58ms/step - loss: 0.1458 - accuracy: 0.9473 - val_loss: 0.1209 - val_accuracy: 0.9607\n",
      "Epoch 18/50\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 0.1358 - accuracy: 0.9520 - val_loss: 0.1179 - val_accuracy: 0.9627\n",
      "Epoch 19/50\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 0.1326 - accuracy: 0.9520 - val_loss: 0.1337 - val_accuracy: 0.9551\n",
      "Epoch 20/50\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 0.1199 - accuracy: 0.9568 - val_loss: 0.1604 - val_accuracy: 0.9234\n",
      "Epoch 21/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0970 - accuracy: 0.9686 - val_loss: 0.0878 - val_accuracy: 0.9773\n",
      "Epoch 22/50\n",
      "214/214 [==============================] - 12s 55ms/step - loss: 0.0894 - accuracy: 0.9725 - val_loss: 0.1256 - val_accuracy: 0.9551\n",
      "Epoch 23/50\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 0.0962 - accuracy: 0.9657 - val_loss: 0.0749 - val_accuracy: 0.9798\n",
      "Epoch 24/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0768 - accuracy: 0.9740 - val_loss: 0.0516 - val_accuracy: 0.9788\n",
      "Epoch 25/50\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 0.0703 - accuracy: 0.9817 - val_loss: 0.0470 - val_accuracy: 0.9874\n",
      "Epoch 26/50\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 0.0556 - accuracy: 0.9835 - val_loss: 0.0668 - val_accuracy: 0.9783\n",
      "Epoch 27/50\n",
      "214/214 [==============================] - 12s 57ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 0.0356 - val_accuracy: 0.9965\n",
      "Epoch 28/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0436 - accuracy: 0.9898 - val_loss: 0.0347 - val_accuracy: 0.9945\n",
      "Epoch 29/50\n",
      "214/214 [==============================] - 11s 51ms/step - loss: 0.0358 - accuracy: 0.9896 - val_loss: 0.0429 - val_accuracy: 0.9909\n",
      "Epoch 30/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0475 - accuracy: 0.9832 - val_loss: -0.0034 - val_accuracy: 0.9940\n",
      "Epoch 31/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0451 - accuracy: 0.9863 - val_loss: 0.0354 - val_accuracy: 0.9914\n",
      "Epoch 32/50\n",
      "214/214 [==============================] - 12s 54ms/step - loss: 0.0306 - accuracy: 0.9926 - val_loss: -0.0092 - val_accuracy: 0.9970\n",
      "Epoch 33/50\n",
      "214/214 [==============================] - 13s 59ms/step - loss: 0.0368 - accuracy: 0.9907 - val_loss: 0.0200 - val_accuracy: 0.9985\n",
      "Epoch 34/50\n",
      "214/214 [==============================] - 12s 56ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0255 - val_accuracy: 0.9950\n",
      "Epoch 35/50\n",
      "214/214 [==============================] - 11s 52ms/step - loss: 0.0266 - accuracy: 0.9934 - val_loss: 0.0114 - val_accuracy: 0.9995\n",
      "Epoch 35: early stopping\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, verbose=True)\n",
    "\n",
    "hist = model.fit(train, validation_data=val, epochs=50, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6d2325bc-b4bb-4fef-9944-03f8ffc01f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 2s 36ms/step - loss: 0.0134 - accuracy: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.013396617956459522, 0.997890293598175]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dd8e0952-2f4c-4f70-bafd-0c5dcc2e1d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"gender_classification.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Trainvenv",
   "language": "python",
   "name": "trainvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
